{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b642114",
   "metadata": {},
   "source": [
    "# Predicting Housing Prices - Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b8f93",
   "metadata": {},
   "source": [
    "In this notebook, I walk through the process of predicting housing prices in Kaggle's housing data competition. I prepare the data using various transformers. After processing the data, I use multiple algorithms and a bayesian optimizer to find the hyperparameters that minimze the error. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182bb97a",
   "metadata": {},
   "source": [
    "## Libraries and Initial Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf516b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries \n",
    "from math import ceil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as ran\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# Optimizer\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# ML Models\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72ab04",
   "metadata": {},
   "source": [
    "Above, I import all the necessary packages. I import general libraries necessary to begin the script. I then import libraries to plot, process the data, score the models, and the necessary algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb16e1d2",
   "metadata": {},
   "source": [
    "Now, I'll do a little set up by pre-setting the seed, the number of crossfolds, importing the training data, finding missing values, and creating a comparison matrix. The comparision matrix will hold the name of the model, it's root mean squared error, and the best hyperparameters from the optimizer. The data frame allows me to compare model performance across each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34302a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random draw of seed for random state #\n",
    "#seed = int(ran.uniform(1, 9999))\n",
    "''' Got 2095 '''\n",
    "seed = 2095\n",
    "\n",
    "\n",
    "# Set mnumber of cross folds #\n",
    "cv = 5\n",
    "\n",
    "\n",
    "# Import training data #\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "# Split into X and Y #\n",
    "X = train.drop(['SalePrice', 'Id'], axis = 1)\n",
    "y = pd.DataFrame(train['SalePrice'])\n",
    "\n",
    "\n",
    "# Find missing values #\n",
    "missing = X.isnull().sum().sort_values(ascending = False)\n",
    "\n",
    "\n",
    "# Make matrix to compare models #\n",
    "train_compare = pd.DataFrame(columns = ['Model', 'RMSE', 'hypers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ff815b",
   "metadata": {},
   "source": [
    "## Initial Alteration of the Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02015e2a",
   "metadata": {},
   "source": [
    "The data frame has many missing values due to not having the feature that is being measured. For example, the frame has a variable call 'PoolQC' that measures the quality of the swiming pool. If the home does not have a pool, then it it labeled as missing. To avoid missing values in the frame, missing values were altered to fit the variable of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c0da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign no pool (NP) to PoolQC #\n",
    "X['PoolQC'].fillna('NP', inplace = True)\n",
    "\n",
    "\n",
    "# Assign no feature (NF) to MiscFeature #\n",
    "X['MiscFeature'].fillna('NF', inplace = True)\n",
    "\n",
    "\n",
    "# Assign no ally (NAL) to Alley #\n",
    "X['Alley'].fillna('NAL', inplace = True)\n",
    "\n",
    "\n",
    "# Assign no fence (NF) to Fence #\n",
    "X['Fence'].fillna('NF', inplace = True)\n",
    "\n",
    "\n",
    "# Assign no fire place (NFP) to FireplaceQu #\n",
    "X['FireplaceQu'].fillna('NFP', inplace = True)\n",
    "\n",
    "\n",
    "# Assign no garage (NG) to GarageType #\n",
    "X['GarageType'].fillna('NG', inplace = True)\n",
    "\n",
    "\n",
    "# Fill garage variables with NG if no garage #\n",
    "garage = ['GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond']\n",
    "for x in garage:\n",
    "    X[x].fillna('NG', inplace = True)\n",
    "del x, garage\n",
    "\n",
    "\n",
    "# Fix GarageYrBlt since it was mixed type #\n",
    "X['GarageYrBlt'] = X['GarageYrBlt'].astype(str)\n",
    "\n",
    "\n",
    "# Fill basement varaibles with no basement (NB) #\n",
    "basement = ['BsmtExposure', 'BsmtFinType2', 'BsmtQual', 'BsmtCond', 'BsmtFinType1']\n",
    "for x in basement:\n",
    "    X[x].fillna('NB', inplace = True)\n",
    "del x, basement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16962ce2",
   "metadata": {},
   "source": [
    "## Plot Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce56c984",
   "metadata": {},
   "source": [
    "After initial set-up, I'll plot the target variable to check for non-normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df2bb577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of Y #\n",
    "plt.hist(y)\n",
    "mean_value = y.mean()\n",
    "median_value = y.median()\n",
    "plt.axvline(mean_value.item(), color='red', linestyle='--', label='Mean')\n",
    "plt.axvline(median_value.item(), color='blue', linestyle='--', label='Median')\n",
    "plt.xlabel('Sale Price')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Histogram of Target Variable')\n",
    "\n",
    "# Add the text to the legend\n",
    "mean_legend = plt.Line2D([], [], color='red', linestyle='--', label=f\"Mean: {mean_value.item():.2f}\")\n",
    "median_legend = plt.Line2D([], [], color='blue', linestyle='--', label=f\"Median: {median_value.item():.2f}\")\n",
    "plt.legend(handles=[mean_legend, median_legend])\n",
    "\n",
    "plt.show()\n",
    "del mean_value, median_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2393a7c",
   "metadata": {},
   "source": [
    "The plot above demonstrates a right skew in the target due to the right tail. In addition, there is distance between the mean and median values of the variable. I'll transform the variable with a natural log function and re-plot the data to ensure normality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39578b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Natural log the target variable #\n",
    "y_log = np.log(y)\n",
    "\n",
    "plt.hist(y_log)\n",
    "mean_value = y_log.mean()\n",
    "median_value = y_log.median()\n",
    "plt.axvline(mean_value.item(), color='red', linestyle='--', label='Mean')\n",
    "plt.axvline(median_value.item(), color='blue', linestyle='--', label='Median')\n",
    "plt.xlabel('Sale Price')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Histogram of Target Variable with Natural Log Transformation')\n",
    "\n",
    "# Add the text to the legend\n",
    "mean_legend = plt.Line2D([], [], color='red', linestyle='--', label=f\"Mean: {mean_value.item():.2f}\")\n",
    "median_legend = plt.Line2D([], [], color='blue', linestyle='--', label=f\"Median: {median_value.item():.2f}\")\n",
    "plt.legend(handles=[mean_legend, median_legend])\n",
    "\n",
    "plt.show()\n",
    "del mean_legend, mean_value, median_legend, median_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b863b3f",
   "metadata": {},
   "source": [
    "After applying the transformation, the target variable is now noramlly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9433b5",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecccf3c",
   "metadata": {},
   "source": [
    "I'll now process the data to ensure is compatible for ML models. I'll split the data into training and validation data, which will be analyzed at the end. After, I encode my categorical variables and implement a KNN imputer. Last, I make a few variables into integer values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e026bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets #\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_log, test_size = 0.25, \n",
    "                                                  random_state = seed)\n",
    "\n",
    "# Mask of numerical features #\n",
    "numeric_feats = X_train.select_dtypes(include = ['int64', 'float64']).columns\n",
    "\n",
    "\n",
    "# Mask categorical features #\n",
    "cat_feats = X_train.select_dtypes(include = ['object']).columns\n",
    "\n",
    "\n",
    "# Encode object variables #\n",
    "ord_enc = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value=np.nan)\n",
    "X_train[cat_feats] = ord_enc.fit_transform(X_train[cat_feats])\n",
    "\n",
    "\n",
    "# Transform X_val with encoder #\n",
    "X_val[cat_feats] = ord_enc.transform(X_val[cat_feats])\n",
    "\n",
    "\n",
    "# KNN Imputer #\n",
    "knn_im = KNNImputer(n_neighbors = 10, weights = 'distance')\n",
    "X_train_imp = pd.DataFrame(knn_im.fit_transform(X_train), columns = X_train.columns)\n",
    "\n",
    "\n",
    "# KNN Imputer for X_val #\n",
    "X_val_imp = pd.DataFrame(knn_im.transform(X_val), columns = X_val.columns)\n",
    "\n",
    "\n",
    "# Variables need to be made integer #\n",
    "X_train_imp[['Electrical', 'MasVnrType', 'GarageYrBlt', 'Exterior1st']] = X_train_imp[['Electrical', 'MasVnrType', 'GarageYrBlt', 'Exterior1st']]\\\n",
    "                                        .apply(lambda x: x.apply(ceil))\n",
    "X_val_imp[['Electrical', 'MasVnrType', 'GarageYrBlt', 'Exterior1st']] = X_val_imp[['Electrical', 'MasVnrType', 'GarageYrBlt', 'Exterior1st']]\\\n",
    "                                        .apply(lambda x: x.apply(ceil))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dddab35",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9848ab",
   "metadata": {},
   "source": [
    "The housing data includes numerous features, and many features are likely to be uncorrelated with the outcome. I limit the number of numeric features with a correlation threshold and the categorical features based on mutual information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68298e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of numeric feats and target #\n",
    "corr_val = pd.concat([X_train_imp[numeric_feats], y_train], axis =1).corr()['SalePrice']\n",
    "\n",
    "\n",
    "# Mask of features with high correlation to target #\n",
    "select_num = list(corr_val[(corr_val >= 0.50) | (corr_val <= -0.50)].index)\n",
    "select_num.remove('SalePrice')\n",
    "\n",
    "\n",
    "# Get mutual information of categorical features and outcome #\n",
    "fs = SelectKBest(score_func = mutual_info_regression, k = 'all')\n",
    "fs.fit(X_train_imp[cat_feats], np.ravel(y_train))\n",
    "\n",
    "\n",
    "# Sort the scores and corresponding feature names in descending order\n",
    "sorted_scores, sorted_features = zip(*sorted(zip(fs.scores_,\n",
    "                                                 X_train_imp[cat_feats].columns),\n",
    "                                             reverse=True))\n",
    "\n",
    "\n",
    "# Select the top 20 features\n",
    "top_20_cat_features = list(sorted_features[:20])\n",
    "\n",
    "\n",
    "# Combine feature selection list #\n",
    "selected_feats = select_num + top_20_cat_features\n",
    "\n",
    "\n",
    "# DF of only selected features #\n",
    "X_train_imp = X_train_imp[selected_feats]\n",
    "X_val_imp = X_val_imp[selected_feats]\n",
    "del corr_val, fs, sorted_features, sorted_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67883e",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f920fa",
   "metadata": {},
   "source": [
    "I now transform my data through categorical and numeric transformers based on the features in the limited data frame. I fit the transformer on the training data and then transform the training and validation data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5377ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#### Transformation ####\n",
    "########################\n",
    "\n",
    "# Categorical transformer #\n",
    "cat_trans = Pipeline(steps = [\n",
    "    ('encode', OneHotEncoder(sparse_output = False))])\n",
    "\n",
    "\n",
    "# Numeric tranformer #\n",
    "num_trans = Pipeline(steps = [\n",
    "    ('stand', StandardScaler())])\n",
    "\n",
    "\n",
    "# Construct processor #\n",
    "processor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', num_trans, select_num),\n",
    "        ('cat', cat_trans, top_20_cat_features)],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "\n",
    "# Apply processor to training data #\n",
    "temp = processor.fit_transform(X_train_imp)\n",
    "\n",
    "\n",
    "# Get categorical feature names #\n",
    "enc_cat_features = list(processor.named_transformers_['cat']['encode']\\\n",
    "                        .get_feature_names_out())\n",
    "\n",
    "\n",
    "# Concat label names #\n",
    "labels = select_num + enc_cat_features \n",
    "\n",
    "\n",
    "# Make df of processed data #\n",
    "X_train = pd.DataFrame(temp, columns = labels)\n",
    "del temp\n",
    "\n",
    "\n",
    "# Apply processor to validation data #\n",
    "temp = processor.transform(X_val_imp)\n",
    "\n",
    "\n",
    "# Get categorical feature names #\n",
    "enc_cat_features = list(processor.named_transformers_['cat']['encode']\\\n",
    "                        .get_feature_names_out())\n",
    "\n",
    "\n",
    "# Concat label names #\n",
    "labels = select_num + enc_cat_features \n",
    "\n",
    "\n",
    "# Make df of processed data #\n",
    "X_val = pd.DataFrame(temp, columns = labels)\n",
    "del temp, y_log, X_val_imp, X_train_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f95ab28",
   "metadata": {},
   "source": [
    "# Start Estimating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b433ca",
   "metadata": {},
   "source": [
    "After preparing the training and validation datasets, the next few sections outline my strategies for predicting the outcome of interest. I'll use seven different estimation strategies that include Ridge, Lasso, Elastic Net, Support Vector Machine, Random Forest, XGBoost, KNN, and a Neural Net in their regression forms. I use a bayesian optimizer to search for the model with the best predictive power. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b58030b",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "096e9ef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   | fit_in... |  solver   |\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "\nPassing acquisition function parameters or gaussian process parameters to maximize\nis no longer supported. Instead,please use the \"set_gp_params\" method to set\n the gp params, and pass an instance of bayes_opt.util.UtilityFunction\n using the acquisition_function argument\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 71\u001b[0m\n\u001b[1;32m     67\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[1;32m     68\u001b[0m     f\u001b[38;5;241m=\u001b[39mobj_ridge, pbounds\u001b[38;5;241m=\u001b[39mpbounds, random_state\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Call maximizer #\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m450\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Pull best info #\u001b[39;00m\n\u001b[1;32m     75\u001b[0m best_hypers \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mmax[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:288\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    286\u001b[0m old_params_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m([param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m [acq, kappa, kappa_decay, kappa_decay_delay, xi]])\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m old_params_used \u001b[38;5;129;01mor\u001b[39;00m gp_params:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPassing acquisition function parameters or gaussian process parameters to maximize\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    289\u001b[0m                              \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mis no longer supported. Instead,please use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_gp_params\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m method to set\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    290\u001b[0m                              \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m the gp params, and pass an instance of bayes_opt.util.UtilityFunction\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    291\u001b[0m                              \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m using the acquisition_function argument\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m acquisition_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m     util \u001b[38;5;241m=\u001b[39m UtilityFunction(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mucb\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    295\u001b[0m                            kappa\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.576\u001b[39m,\n\u001b[1;32m    296\u001b[0m                            xi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    297\u001b[0m                            kappa_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    298\u001b[0m                            kappa_decay_delay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: \nPassing acquisition function parameters or gaussian process parameters to maximize\nis no longer supported. Instead,please use the \"set_gp_params\" method to set\n the gp params, and pass an instance of bayes_opt.util.UtilityFunction\n using the acquisition_function argument\n"
     ]
    }
   ],
   "source": [
    "# Define objective for ridge #\n",
    "def obj_ridge(alpha, fit_intercept, solver):\n",
    "    \n",
    "    \"\"\"\n",
    "    Objective function to minimize the error of the \n",
    "    ridge regression.    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : L2 Regularization term.\n",
    "        Regularizes the coefficients. Values stipulated\n",
    "        in pbounds.\n",
    "    fit_intercept : Boolean of fit intercept.\n",
    "        Indicator of whether or not the model\n",
    "        fits an intercept.\n",
    "    solver : Solving method of ridge regression.\n",
    "        Continuous variable for selecting the best\n",
    "        solver for the regression.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error : Mean squared error.\n",
    "        Cross validation returns root mean error that is later\n",
    "        convereted into RMSE in the comparison frame.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fit intercept #\n",
    "    fit_intercept = bool(round(fit_intercept))\n",
    "    \n",
    "    # Solver #\n",
    "    if solver <= 1.0:\n",
    "        solver = 'auto'\n",
    "    elif solver <= 2.0:\n",
    "        solver = 'svd'\n",
    "    elif solver <= 3.0:\n",
    "        solver = 'cholesky'\n",
    "    elif solver <= 4.0:\n",
    "        solver = 'lsqr'\n",
    "    elif solver <= 5.0:\n",
    "        solver = 'sparse_cg'\n",
    "    elif solver <= 6.0:\n",
    "        solver = 'sag'\n",
    "    else:\n",
    "        solver = 'saga'\n",
    "    \n",
    "    # Instantiate ridge model #\n",
    "    model = Ridge(alpha=alpha, fit_intercept=fit_intercept, solver=solver,\n",
    "                  max_iter = 20000, random_state=seed)\n",
    "    \n",
    "    # Cross validation and mean MSE #\n",
    "    error = cross_val_score(model, X_train, y_train, cv=cv,\n",
    "                            scoring='neg_mean_squared_error').mean()\n",
    "    \n",
    "    # Return error #\n",
    "    return error\n",
    "\n",
    "\n",
    "# Define search space #\n",
    "pbounds = {\n",
    "    'alpha': (0.00000001, 100),\n",
    "    'fit_intercept': (0, 1),\n",
    "    'solver': (0, 8),\n",
    "}\n",
    "\n",
    "# Set the optimizer #\n",
    "optimizer = BayesianOptimization(\n",
    "    f=obj_ridge, pbounds=pbounds, random_state=seed)\n",
    "\n",
    "# Call maximizer #\n",
    "optimizer.maximize(init_points=50, n_iter=450)\n",
    "\n",
    "\n",
    "# Pull best info #\n",
    "best_hypers = optimizer.max['params']\n",
    "best_mse = optimizer.max['target']\n",
    "\n",
    "\n",
    "# Replace solver with string #\n",
    "if best_hypers['solver'] <= 1.0:\n",
    "    best_hypers['solver']  = 'auto'\n",
    "elif best_hypers['solver']  <= 2.0:\n",
    "    best_hypers['solver']  = 'svd'\n",
    "elif best_hypers['solver']  <= 3.0:\n",
    "    best_hypers['solver']  = 'cholesky'\n",
    "elif best_hypers['solver']  <= 4.0:\n",
    "    best_hypers['solver']  = 'lsqr'\n",
    "elif best_hypers['solver']  <= 5.0:\n",
    "    best_hypers['solver']  = 'sparse_cg'\n",
    "elif best_hypers['solver']  <= 6.0:\n",
    "    best_hypers['solver']  = 'sag'\n",
    "else:\n",
    "    best_hypers['solver']  = 'saga'\n",
    "\n",
    "\n",
    "# Fill comparison matrix #\n",
    "train_compare = pd.concat([train_compare,\n",
    "                           pd.DataFrame({'Model' : 'Ridge',\n",
    "                            'RMSE': np.sqrt(best_mse * -1),\n",
    "                            'hypers': [best_hypers]})], ignore_index = True)\n",
    "\n",
    "\n",
    "# Sort by smallest RMSE #\n",
    "train_compare = train_compare.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381372b",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a9c6c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   | fit_in... | selection |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m54.96    \u001b[0m | \u001b[0m0.04263  \u001b[0m | \u001b[0m0.1776   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m26.97    \u001b[0m | \u001b[0m0.2803   \u001b[0m | \u001b[0m0.7405   \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-0.1597  \u001b[0m | \u001b[95m37.77    \u001b[0m | \u001b[95m0.7732   \u001b[0m | \u001b[95m0.2801   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m78.0     \u001b[0m | \u001b[0m0.7002   \u001b[0m | \u001b[0m0.6631   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m36.86    \u001b[0m | \u001b[0m0.7854   \u001b[0m | \u001b[0m0.1763   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m37.67    \u001b[0m | \u001b[0m0.5094   \u001b[0m | \u001b[0m0.9447   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m36.78    \u001b[0m | \u001b[0m0.9452   \u001b[0m | \u001b[0m0.4155   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m38.87    \u001b[0m | \u001b[0m0.5653   \u001b[0m | \u001b[0m0.4373   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-28.32   \u001b[0m | \u001b[0m4.091    \u001b[0m | \u001b[0m0.3928   \u001b[0m | \u001b[0m0.9653   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m82.5     \u001b[0m | \u001b[0m0.6042   \u001b[0m | \u001b[0m0.1234   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m28.64    \u001b[0m | \u001b[0m0.1985   \u001b[0m | \u001b[0m0.1038   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m10.73    \u001b[0m | \u001b[0m0.7565   \u001b[0m | \u001b[0m0.8618   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m72.14    \u001b[0m | \u001b[0m0.01208  \u001b[0m | \u001b[0m0.3532   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m15.38    \u001b[0m | \u001b[0m0.9466   \u001b[0m | \u001b[0m0.3479   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m89.71    \u001b[0m | \u001b[0m0.06589  \u001b[0m | \u001b[0m0.2792   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m53.77    \u001b[0m | \u001b[0m0.5269   \u001b[0m | \u001b[0m0.3273   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m80.05    \u001b[0m | \u001b[0m0.5179   \u001b[0m | \u001b[0m0.2346   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m67.05    \u001b[0m | \u001b[0m0.2801   \u001b[0m | \u001b[0m0.1811   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m64.76    \u001b[0m | \u001b[0m0.1135   \u001b[0m | \u001b[0m0.561    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-108.1   \u001b[0m | \u001b[0m9.279    \u001b[0m | \u001b[0m0.3167   \u001b[0m | \u001b[0m0.2266   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m30.13    \u001b[0m | \u001b[0m0.1911   \u001b[0m | \u001b[0m0.09858  \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-7.594   \u001b[0m | \u001b[0m0.9014   \u001b[0m | \u001b[0m0.1357   \u001b[0m | \u001b[0m0.9071   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m79.73    \u001b[0m | \u001b[0m0.1496   \u001b[0m | \u001b[0m0.6123   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m63.1     \u001b[0m | \u001b[0m0.409    \u001b[0m | \u001b[0m0.2611   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m29.4     \u001b[0m | \u001b[0m0.2363   \u001b[0m | \u001b[0m0.3779   \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m60.9     \u001b[0m | \u001b[0m0.475    \u001b[0m | \u001b[0m0.5773   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m39.73    \u001b[0m | \u001b[0m0.6594   \u001b[0m | \u001b[0m0.4477   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m79.59    \u001b[0m | \u001b[0m0.7388   \u001b[0m | \u001b[0m0.2747   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m58.88    \u001b[0m | \u001b[0m0.5334   \u001b[0m | \u001b[0m0.5892   \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m84.7     \u001b[0m | \u001b[0m0.6611   \u001b[0m | \u001b[0m0.1778   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m85.84    \u001b[0m | \u001b[0m0.61     \u001b[0m | \u001b[0m0.2359   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m30.91    \u001b[0m | \u001b[0m0.3807   \u001b[0m | \u001b[0m0.6225   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m84.87    \u001b[0m | \u001b[0m0.2703   \u001b[0m | \u001b[0m0.5373   \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m1.946    \u001b[0m | \u001b[0m0.774    \u001b[0m | \u001b[0m0.03822  \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m26.56    \u001b[0m | \u001b[0m0.8447   \u001b[0m | \u001b[0m0.603    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m59.12    \u001b[0m | \u001b[0m0.8245   \u001b[0m | \u001b[0m0.9916   \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m24.5     \u001b[0m | \u001b[0m0.2188   \u001b[0m | \u001b[0m0.1304   \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m27.2     \u001b[0m | \u001b[0m0.002769 \u001b[0m | \u001b[0m0.2502   \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m21.81    \u001b[0m | \u001b[0m0.6404   \u001b[0m | \u001b[0m0.6046   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m42.91    \u001b[0m | \u001b[0m0.928    \u001b[0m | \u001b[0m0.1626   \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m80.48    \u001b[0m | \u001b[0m0.9119   \u001b[0m | \u001b[0m0.705    \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m11.78    \u001b[0m | \u001b[0m0.3683   \u001b[0m | \u001b[0m0.9416   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m55.88    \u001b[0m | \u001b[0m0.9225   \u001b[0m | \u001b[0m0.02617  \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m59.69    \u001b[0m | \u001b[0m0.5321   \u001b[0m | \u001b[0m0.1384   \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m39.71    \u001b[0m | \u001b[0m0.7999   \u001b[0m | \u001b[0m0.419    \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m38.63    \u001b[0m | \u001b[0m0.892    \u001b[0m | \u001b[0m0.8402   \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m96.73    \u001b[0m | \u001b[0m0.1582   \u001b[0m | \u001b[0m0.8151   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m28.36    \u001b[0m | \u001b[0m0.525    \u001b[0m | \u001b[0m0.4459   \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m81.05    \u001b[0m | \u001b[0m0.4531   \u001b[0m | \u001b[0m0.3147   \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m77.79    \u001b[0m | \u001b[0m0.8044   \u001b[0m | \u001b[0m0.03502  \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m9.135    \u001b[0m | \u001b[0m0.5831   \u001b[0m | \u001b[0m0.5583   \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m80.03    \u001b[0m | \u001b[0m0.9309   \u001b[0m | \u001b[0m0.05158  \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m38.27    \u001b[0m | \u001b[0m0.3615   \u001b[0m | \u001b[0m0.5514   \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m63.26    \u001b[0m | \u001b[0m0.2264   \u001b[0m | \u001b[0m0.5376   \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m37.32    \u001b[0m | \u001b[0m0.8138   \u001b[0m | \u001b[0m0.5986   \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m93.52    \u001b[0m | \u001b[0m0.1462   \u001b[0m | \u001b[0m0.4189   \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m39.22    \u001b[0m | \u001b[0m0.8458   \u001b[0m | \u001b[0m0.7801   \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m98.97    \u001b[0m | \u001b[0m0.4474   \u001b[0m | \u001b[0m0.7095   \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m59.3     \u001b[0m | \u001b[0m0.9731   \u001b[0m | \u001b[0m0.3851   \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m56.85    \u001b[0m | \u001b[0m0.9239   \u001b[0m | \u001b[0m0.009167 \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m39.05    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1478   \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m8.699    \u001b[0m | \u001b[0m0.9833   \u001b[0m | \u001b[0m0.9007   \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m0.9977   \u001b[0m | \u001b[0m0.9467   \u001b[0m | \u001b[0m0.3317   \u001b[0m |\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m1.534    \u001b[0m | \u001b[0m0.5048   \u001b[0m | \u001b[0m0.5958   \u001b[0m |\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m-8.842   \u001b[0m | \u001b[0m1.203    \u001b[0m | \u001b[0m0.2966   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m53.77    \u001b[0m | \u001b[0m0.5145   \u001b[0m | \u001b[0m0.3519   \u001b[0m |\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m9.722    \u001b[0m | \u001b[0m0.9488   \u001b[0m | \u001b[0m0.9707   \u001b[0m |\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m84.18    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m30.59    \u001b[0m | \u001b[0m0.325    \u001b[0m | \u001b[0m0.1417   \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m40.44    \u001b[0m | \u001b[0m0.2876   \u001b[0m | \u001b[0m0.3049   \u001b[0m |\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m28.2     \u001b[0m | \u001b[0m0.9219   \u001b[0m | \u001b[0m0.8834   \u001b[0m |\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m78.64    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.07504  \u001b[0m |\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m56.38    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6942   \u001b[0m |\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m17.68    \u001b[0m | \u001b[0m0.7541   \u001b[0m | \u001b[0m0.009239 \u001b[0m |\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m70.09    \u001b[0m | \u001b[0m0.9612   \u001b[0m | \u001b[0m0.6774   \u001b[0m |\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m36.87    \u001b[0m | \u001b[0m0.1884   \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m80.31    \u001b[0m | \u001b[0m0.5603   \u001b[0m | \u001b[0m0.8173   \u001b[0m |\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m56.58    \u001b[0m | \u001b[0m0.2696   \u001b[0m | \u001b[0m0.3433   \u001b[0m |\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m83.29    \u001b[0m | \u001b[0m0.6107   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m-144.9   \u001b[0m | \u001b[0m78.28    \u001b[0m | \u001b[0m0.2276   \u001b[0m | \u001b[0m0.01261  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m81       \u001b[0m | \u001b[0m-0.1597  \u001b[0m | \u001b[0m77.24    \u001b[0m | \u001b[0m0.9987   \u001b[0m | \u001b[0m0.7775   \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:305\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_queue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:27\u001b[0m, in \u001b[0;36mQueue.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueue is empty, no more objects to retrieve.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 64\u001b[0m\n\u001b[1;32m     60\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[1;32m     61\u001b[0m     f\u001b[38;5;241m=\u001b[39mobj_lasso, pbounds\u001b[38;5;241m=\u001b[39mpbounds, random_state\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Call maximizer #\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m450\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Pull best info #\u001b[39;00m\n\u001b[1;32m     68\u001b[0m best_hypers \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mmax[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:308\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     util\u001b[38;5;241m.\u001b[39mupdate_params()\n\u001b[0;32m--> 308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mutil\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:220\u001b[0m, in \u001b[0;36mBayesianOptimization.suggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    219\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_constrained:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mparams,\n\u001b[1;32m    223\u001b[0m                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39m_constraint_values)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:304\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer):\n\u001b[1;32m    302\u001b[0m         theta_initial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39muniform(bounds[:, \u001b[38;5;241m0\u001b[39m], bounds[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    303\u001b[0m         optima\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 304\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m         )\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Select result from run with minimal (negative) log-marginal\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# likelihood\u001b[39;00m\n\u001b[1;32m    308\u001b[0m lml_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(itemgetter(\u001b[38;5;241m1\u001b[39m), optima))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:622\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 622\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[1;32m    630\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/scipy/optimize/_minimize.py:696\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    693\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    694\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 696\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    699\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    700\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:359\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    353\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:276\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 276\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:593\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    591\u001b[0m inner_term \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mik,jk->ijk\u001b[39m\u001b[38;5;124m\"\u001b[39m, alpha, alpha)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# compute K^-1 of shape (n_samples, n_samples)\u001b[39;00m\n\u001b[0;32m--> 593\u001b[0m K_inv \u001b[38;5;241m=\u001b[39m \u001b[43mcho_solve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGPR_CHOLESKY_LOWER\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    595\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;66;03m# create a new axis to use broadcasting between inner_term and\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# K_inv\u001b[39;00m\n\u001b[1;32m    598\u001b[0m inner_term \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m K_inv[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py:211\u001b[0m, in \u001b[0;36mcho_solve\u001b[0;34m(c_and_lower, b, overwrite_b, check_finite)\u001b[0m\n\u001b[1;32m    208\u001b[0m overwrite_b \u001b[38;5;241m=\u001b[39m overwrite_b \u001b[38;5;129;01mor\u001b[39;00m _datacopied(b1, b)\n\u001b[1;32m    210\u001b[0m potrs, \u001b[38;5;241m=\u001b[39m get_lapack_funcs((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpotrs\u001b[39m\u001b[38;5;124m'\u001b[39m,), (c, b1))\n\u001b[0;32m--> 211\u001b[0m x, info \u001b[38;5;241m=\u001b[39m \u001b[43mpotrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124millegal value in \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mth argument of internal potrs\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    214\u001b[0m                      \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m-\u001b[39minfo)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define objective function for lasso #\n",
    "def obj_lasso(alpha, fit_intercept,\n",
    "              selection): \n",
    "    \n",
    "    \"\"\"\n",
    "    The objective of this function is to minimize the error\n",
    "    of the lasso function. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : L1 Regularization term.\n",
    "        Regularizes the coefficients. Values stipulated\n",
    "        in pbounds.\n",
    "    fit_intercept : Boolean of fit intercept.\n",
    "        Indicator of whether or not the model\n",
    "        fits an intercept.\n",
    "    selection : Dictates coefficient updates.\n",
    "        Continuous variable of using either cycle or\n",
    "        random for coefficient update.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error : Mean squared error.\n",
    "        Cross validation returns root mean error that is later\n",
    "        convereted into RMSE in the comparison frame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fit intercept #\n",
    "    fit_intercept = bool(round(fit_intercept))\n",
    "    \n",
    "    \n",
    "    # selection #\n",
    "    if selection <= 0.5:\n",
    "        selection = 'cyclic'\n",
    "    else:\n",
    "        selection = 'random'\n",
    "    \n",
    "    # Instantiate model #\n",
    "    model = Lasso(alpha = alpha, fit_intercept = fit_intercept,\n",
    "                  selection = selection,\n",
    "                  random_state = seed, max_iter = 20000)\n",
    "    \n",
    "    # Cross validation and mean MSE #\n",
    "    error = cross_val_score(model, X_train, y_train, cv=cv,\n",
    "                            scoring='neg_mean_squared_error').mean()\n",
    "    \n",
    "    # Return error #\n",
    "    return error\n",
    "\n",
    "\n",
    "# Define search space #\n",
    "pbounds = {\n",
    "    'alpha': (0.0000001, 100),\n",
    "    'fit_intercept': (0, 1),\n",
    "    'selection': (0, 1)\n",
    "}\n",
    "\n",
    "\n",
    "# Set the optimizer #\n",
    "optimizer = BayesianOptimization(\n",
    "    f=obj_lasso, pbounds=pbounds, random_state=seed)\n",
    "\n",
    "# Call maximizer #\n",
    "optimizer.maximize(init_points = 50, n_iter = 450)\n",
    "\n",
    "\n",
    "# Pull best info #\n",
    "best_hypers = optimizer.max['params']\n",
    "best_mse = optimizer.max['target']\n",
    "\n",
    "\n",
    "# Replace selection with string #\n",
    "if best_hypers['selection'] <= 0.5:\n",
    "    best_hypers['selection'] = 'cyclic'\n",
    "else:\n",
    "    best_hypers['selection'] = 'random'\n",
    "\n",
    "\n",
    "# Fill comparison matrix #\n",
    "train_compare = pd.concat([train_compare,\n",
    "                           pd.DataFrame({'Model' : 'Lasso',\n",
    "                            'RMSE': np.sqrt(best_mse * -1),\n",
    "                            'hypers': [best_hypers]})], ignore_index = True)\n",
    "\n",
    "train_compare = train_compare.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622f922",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0c004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function for Net #\n",
    "def obj_net(alpha, l1_ratio, fit_intercept,\n",
    "            selection):\n",
    "    \"\"\"\n",
    "    The objective of this function is to minimize the error\n",
    "    of the elastic net model. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : Float\n",
    "        Constant the multiplies the penalty terms. 0 is equal to OLS.\n",
    "    l1_ratio : Float\n",
    "        Ratio of l1 or l2 regularization. 0 is l2. 1 is l1.\n",
    "    fit_intercept : bool\n",
    "        Option to fit an intercept.\n",
    "    selection : String\n",
    "        Specify how coefficients are updated across iterations. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error : Float\n",
    "        Cross validation returns root mean error that is later\n",
    "        convereted into RMSE in the comparison frame.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Vary fit intercept #\n",
    "    fit_intercept = bool(round(fit_intercept))\n",
    "\n",
    "    # Vary selection #\n",
    "    if selection <= 0.5:\n",
    "        selection = 'cyclic'\n",
    "    else:\n",
    "        selection = 'random'\n",
    "        \n",
    "    # Instantiate the model #\n",
    "    model = ElasticNet(alpha = alpha, l1_ratio = l1_ratio,\n",
    "                       fit_intercept =  fit_intercept,\n",
    "                       selection = selection, random_state = seed,\n",
    "                       max_iter = 20000)\n",
    "    \n",
    "    # Cross validation and mean MSE #\n",
    "    error = cross_val_score(model, X_train, np.ravel(y_train), cv=cv,\n",
    "                            scoring='neg_mean_squared_error').mean()\n",
    "    \n",
    "    # Return error #\n",
    "    return error\n",
    "\n",
    "# Define search space #\n",
    "pbounds = {\n",
    "    'alpha': (0.00001, 100),\n",
    "    'l1_ratio': (0.001, 0.99),\n",
    "    'fit_intercept': (0, 1),\n",
    "    'selection': (0, 1)\n",
    "}   \n",
    "\n",
    "\n",
    "# Set the optimizer #\n",
    "optimizer = BayesianOptimization(\n",
    "    f=obj_net, pbounds=pbounds, random_state=seed)\n",
    "\n",
    "\n",
    "# Call maximizer #\n",
    "optimizer.maximize(init_points = 50, n_iter = 450)\n",
    "\n",
    "\n",
    "# Pull best info #\n",
    "best_hypers = optimizer.max['params']\n",
    "best_mse = optimizer.max['target']\n",
    "\n",
    "\n",
    "# Replace selection with string #\n",
    "if best_hypers['selection'] <= 0.5:\n",
    "    best_hypers['selection']  = 'cyclic'\n",
    "else:\n",
    "    best_hypers['selection']  = 'random'\n",
    "\n",
    "\n",
    "# Fill comparison matrix #\n",
    "train_compare = pd.concat([train_compare,\n",
    "                           pd.DataFrame({'Model' : 'Elastic_Net',\n",
    "                            'RMSE': np.sqrt(best_mse * -1),\n",
    "                            'hypers': [best_hypers]})], ignore_index = True)\n",
    "\n",
    "train_compare = train_compare.sort_values('RMSE') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af775a64",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0140de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function for SVM #\n",
    "def obj_SVR(kernel, degree,\n",
    "            gamma, C, epsilon, \n",
    "            shrinking):\n",
    "    \"\"\"\n",
    "    The objective of this function is to minimze the erro\n",
    "    of the support vector regression.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kernel : Kernel used in solver.\n",
    "        String inputs that are used in optimizer.\n",
    "    degree : Degree of polyomial kernel.\n",
    "        Only used in poly alogrithm.\n",
    "    gamma : Kernel cofficient.\n",
    "        Only used in rbf, poly, and sigmoid.\n",
    "    C : L2 regularizer.\n",
    "        More regularization at smaller values.\n",
    "    epsilon : Epplison value in SVR model.\n",
    "        Specifies penalty in training loss function.\n",
    "    shrinking : Boolean value.\n",
    "        Dictates if the model uses shrinking heuristic.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error : Mean squared error.\n",
    "        Cross validation returns root mean error that is later\n",
    "        convereted into RMSE in the comparison frame.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Kernel #\n",
    "    if kernel <= 1:\n",
    "        kernel = 'linear'\n",
    "    elif kernel <= 2:\n",
    "        kernel = 'poly'\n",
    "    elif kernel <= 3:\n",
    "        kernel = 'rbf'\n",
    "    else:\n",
    "        kernel = 'sigmoid'\n",
    "    \n",
    "    # Gamma #\n",
    "    if gamma <= 0.5:\n",
    "        gamma = 'scale'\n",
    "    else:\n",
    "        gamma = 'auto'\n",
    "        \n",
    "    # Shrinking #\n",
    "    shrinking = bool(round(shrinking))\n",
    "        \n",
    "    # Instantiate SVR #\n",
    "    model = SVR(kernel =  kernel, degree = int(degree),\n",
    "                gamma = gamma, C = C,\n",
    "                epsilon = epsilon, shrinking = shrinking,\n",
    "                max_iter = 50000)\n",
    "    \n",
    "    # Cross validation and mean MSE #\n",
    "    error = cross_val_score(model, X_train, np.ravel(y_train), cv=cv,\n",
    "                            scoring='neg_mean_squared_error').mean()\n",
    "    \n",
    "    # Return error #\n",
    "    return error\n",
    "    \n",
    "\n",
    "# Define search space #\n",
    "pbounds = {\n",
    "    'kernel': (0, 4),\n",
    "    'degree': (1, 10),\n",
    "    'gamma': (0, 1),\n",
    "    'C': (0.0001, 100),\n",
    "    'epsilon': (0.0001, 100),\n",
    "    'shrinking': (0, 1)\n",
    "}\n",
    "\n",
    "\n",
    "# Set the optimizer #\n",
    "optimizer = BayesianOptimization(\n",
    "    f=obj_SVR, pbounds=pbounds, random_state=seed)\n",
    "\n",
    "\n",
    "# Call maximizer #\n",
    "optimizer.maximize(init_points = 50, n_iter = 450)\n",
    "\n",
    "\n",
    "# Pull best info #\n",
    "best_hypers = optimizer.max['params']\n",
    "best_mse = optimizer.max['target']\n",
    "\n",
    "\n",
    "# Replace kernel with string #\n",
    "if best_hypers['kernel'] <= 1:\n",
    "    best_hypers['kernel'] = 'linear'\n",
    "elif best_hypers['kernel'] <= 2:\n",
    "    best_hypers['kernel'] = 'poly'\n",
    "elif best_hypers['kernel'] <= 3:\n",
    "    best_hypers['kernel'] = 'rbf'\n",
    "else:\n",
    "    best_hypers['kernel'] = 'sigmoid'\n",
    "    \n",
    "\n",
    "# Replace gamma with string #\n",
    "if best_hypers['gamma'] <= 0.5:\n",
    "    best_hypers['gamma'] = 'scale'\n",
    "else:\n",
    "    best_hypers['gamma'] = 'auto'\n",
    "\n",
    "\n",
    "# Fill comparison matrix #\n",
    "train_compare = pd.concat([train_compare,\n",
    "                           pd.DataFrame({'Model' : 'SVR',\n",
    "                            'RMSE': np.sqrt(best_mse * -1),\n",
    "                            'hypers': [best_hypers]})], ignore_index = True)\n",
    "\n",
    "train_compare = train_compare.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9447ba6",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function for random forest #\n",
    "def obj_RF(n_estimators, criterion,\n",
    "           min_samples_split, min_samples_leaf,\n",
    "           max_features, bootstrap, min_impurity_decrease):\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_estimators : Float\n",
    "        Number of trees to estimate in the forest.\n",
    "    criterion : String\n",
    "        How the tree measures quality of the split.\n",
    "    min_samples_split : Float\n",
    "        Minimum number of samples required to split a node.\n",
    "    min_samples_leaf : Float\n",
    "        Minimum number of samples required to be a leaf.\n",
    "    max_features : String\n",
    "        Number of features to consider when splitting.\n",
    "    bootstrap : Boolean\n",
    "        Whether bootstraps are used when building trees.\n",
    "    min_impurity_decrease : Float\n",
    "        Node is split if it decreases the impurity.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error : Mean squared error.\n",
    "        Cross validation returns root mean error that is later\n",
    "        convereted into RMSE in the comparison frame.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Criterion #\n",
    "    if criterion <= 1.0:\n",
    "        criterion = 'squared_error'\n",
    "    elif criterion <= 2.0:\n",
    "        criterion = 'absolute_error'\n",
    "    elif criterion <= 3.0:\n",
    "        criterion = 'friedman_mse'\n",
    "    else:\n",
    "        criterion = 'poisson'\n",
    "        \n",
    "    # Max features #\n",
    "    if max_features <= 0.5:\n",
    "        max_features = 'sqrt'\n",
    "    else:\n",
    "        max_features = 'log2'\n",
    "        \n",
    "    # Bootstrap #\n",
    "    bootstrap = bool(round(bootstrap))\n",
    "    \n",
    "    # instantiate random forest moel #\n",
    "    model = RFR(n_estimators = int(n_estimators), criterion = criterion,\n",
    "                min_samples_split =  min_samples_split,\n",
    "                min_samples_leaf = min_samples_leaf,\n",
    "                max_features =  max_features, bootstrap =  bootstrap,\n",
    "                min_impurity_decrease = min_impurity_decrease,\n",
    "                n_jobs = -1, random_state = seed)\n",
    "    \n",
    "    # Cross validation and mean MSE #\n",
    "    error = cross_val_score(model, X_train, np.ravel(y_train), cv=cv,\n",
    "                            scoring='neg_mean_squared_error').mean()\n",
    "    \n",
    "    # Return error #\n",
    "    return error\n",
    "\n",
    "\n",
    "# Define search space #\n",
    "pbounds = {\n",
    "    'n_estimators': (1, 1000),\n",
    "    'criterion': (0, 4),\n",
    "    'min_samples_split': (0.01, .70),\n",
    "    'min_samples_leaf': (0.01, .70),\n",
    "    'max_features': (0, 1),\n",
    "    'bootstrap': (0, 1),\n",
    "    'min_impurity_decrease': (0.001, 0.4)\n",
    "}\n",
    "\n",
    "\n",
    "# Set the optimizer #\n",
    "optimizer = BayesianOptimization(\n",
    "    f=obj_RF, pbounds=pbounds, random_state=seed)\n",
    "\n",
    "\n",
    "# Call maximizer #\n",
    "optimizer.maximize(init_points = 50, n_iter = 450,)\n",
    "\n",
    "\n",
    "# Pull best info #\n",
    "best_hypers = optimizer.max['params']\n",
    "best_mse = optimizer.max['target']\n",
    "\n",
    "\n",
    "# Replace criterion with string #\n",
    "if best_hypers['criterion'] <= 1.0:\n",
    "    best_hypers['criterion'] = 'squared_error'\n",
    "elif best_hypers['criterion'] <= 2.0:\n",
    "    best_hypers['criterion'] = 'absolute_error'\n",
    "elif best_hypers['criterion'] <= 3.0:\n",
    "    best_hypers['criterion'] = 'friedman_mse'\n",
    "else:\n",
    "    best_hypers['criterion'] = 'poisson'\n",
    "        \n",
    "\n",
    "# Replace max features with string #\n",
    "if best_hypers['max_features'] <= 0.5:\n",
    "    best_hypers['max_features'] = 'sqrt'\n",
    "else:\n",
    "    best_hypers['max_features'] = 'log2'\n",
    "        \n",
    "\n",
    "# Fill comparison matrix #\n",
    "train_compare = pd.concat([train_compare,\n",
    "                           pd.DataFrame({'Model' : 'Random_Forest',\n",
    "                            'RMSE': np.sqrt(best_mse * -1),\n",
    "                            'hypers': [best_hypers]})], ignore_index = True)\n",
    "\n",
    "train_compare = train_compare.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84a1b2",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f39e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function for XGBoost regression #\n",
    "def obj_boost(n_estimators, eta, gamma, \n",
    "              max_depth, subsample, colsample_bytree,\n",
    "              reg_lambda, alpha):\n",
    "    \"\"\"\n",
    "    The objective of this function is to minimze the error\n",
    "    of the XGBoosted random forest regression. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_estimators : Integer\n",
    "        Number of trees to estimate.\n",
    "    eta : Float\n",
    "        Feature weight shrinkage that prevents overfitting.\n",
    "    gamma : Float\n",
    "        Min loss reduction needed to make partition on a leaf node.\n",
    "    max_depth : Int\n",
    "        Maximum depth of a tree. Deeper trees increase overfitting.\n",
    "    subsample : Float\n",
    "        Subsample of the dataset to use in tree.\n",
    "    colsample_bytree : Float\n",
    "        Subsample of columns to use in each tree.\n",
    "    reg_lambda : Float\n",
    "        L2 regularization on weights. Higher values make models more conservative.\n",
    "    alpha : Float\n",
    "        L1 regularization on weights. Higher values make models more conservative.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error : Float\n",
    "        Cross validation returns root mean error that is later\n",
    "        convereted into RMSE in the comparison frame.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # instantiate XGBoost #\n",
    "    model = XGBRegressor(n_estimators = int(n_estimators), eta = eta,\n",
    "                         gamma = gamma, max_depth = int(max_depth),\n",
    "                         subsample = subsample, colsample_bytree = colsample_bytree,\n",
    "                         reg_lambda = reg_lambda, alpha = alpha, \n",
    "                         seed = seed, n_jobs = 1)\n",
    "    \n",
    "    # Cross validation and mean MSE #\n",
    "    error = cross_val_score(model, X_train, np.ravel(y_train), cv=cv,\n",
    "                            scoring='neg_mean_squared_error').mean()\n",
    "    \n",
    "    # Return error #\n",
    "    return error\n",
    "\n",
    "    \n",
    "# Define the search space #\n",
    "pbounds = {\n",
    "    'n_estimators': (1, 2000),\n",
    "    'eta': (0, 1),\n",
    "    'gamma': (0, 5),\n",
    "    'max_depth': (2, 7),\n",
    "    'subsample': (0.5, 1),\n",
    "    'colsample_bytree': (0.2, 0.9),\n",
    "    'reg_lambda': (0.05, 10),\n",
    "    'alpha': (0.05, 10)\n",
    "}\n",
    "\n",
    "\n",
    "# Set the optimizer #\n",
    "optimizer = BayesianOptimization(\n",
    "    f=obj_boost, pbounds=pbounds, random_state=seed)\n",
    "\n",
    "\n",
    "# Call maximizer #\n",
    "optimizer.maximize(init_points = 50, n_iter = 450)\n",
    "\n",
    "\n",
    "# Pull best info #\n",
    "best_hypers = optimizer.max['params']\n",
    "best_mse = optimizer.max['target']\n",
    "\n",
    "\n",
    "# Fill comparison matrix #\n",
    "train_compare = pd.concat([train_compare,\n",
    "                           pd.DataFrame({'Model' : 'XGBoost_Reg',\n",
    "                            'RMSE': np.sqrt(best_mse * -1),\n",
    "                            'hypers': [best_hypers]})], ignore_index = True)\n",
    "\n",
    "train_compare = train_compare.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9223a333",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99702e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function for K-Nearest Neighbors #\n",
    "def obj_knn(n_neighbors, weights, algorithm,\n",
    "            leaf_size, p):\n",
    "    \"\"\"\n",
    "    This objective function minimzes the error for k-nearest\n",
    "    neighbors regression.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_neighbors : int\n",
    "        Number of neighbors to use.\n",
    "    weights : String\n",
    "        Weight function used in prediction.\n",
    "    algorithm : String\n",
    "        Process used to compute the nearest neighbors.\n",
    "    leaf_size : int\n",
    "        Leaf size passed to specific algorithms.\n",
    "    p : int\n",
    "        Power parameter for Minkowski metric.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error : Float\n",
    "        Cross validation returns root mean error that is later\n",
    "        convereted into RMSE in the comparison frame.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Variation on weights #\n",
    "    if weights <= 0.5:\n",
    "        weights = 'uniform'\n",
    "    else:\n",
    "        weights = 'distance'\n",
    "    \n",
    "    # Variation on algorithm #\n",
    "    if algorithm <= 1.0:\n",
    "        algorithm = 'auto'\n",
    "    elif algorithm <= 2.0:\n",
    "        algorithm = 'ball_tree'\n",
    "    elif algorithm <= 3.0:\n",
    "        algorithm = 'kd_tree'\n",
    "    else:\n",
    "        algorithm = 'brute'\n",
    "    \n",
    "    # Variation on p #\n",
    "    if p <= 1.0:\n",
    "        p = 1\n",
    "    elif p <= 1.0 and algorithm != 'brute':\n",
    "        p = 1\n",
    "    else:\n",
    "        p = 2\n",
    "    \n",
    "    # Instantiate model #\n",
    "    model = KNeighborsRegressor(n_neighbors =  int(n_neighbors), weights = weights,\n",
    "                                algorithm = algorithm, leaf_size = int(leaf_size), p = p)\n",
    "    \n",
    "    # Cross validation and mean MSE #\n",
    "    error = cross_val_score(model, X_train, np.ravel(y_train), cv=cv,\n",
    "                            scoring='neg_mean_squared_error').mean()\n",
    "    \n",
    "    # Return error #\n",
    "    return error\n",
    "    \n",
    "\n",
    "# Define search space #\n",
    "pbounds = {\n",
    "    'n_neighbors': (2, 10),\n",
    "    'weights': (0, 1),\n",
    "    'algorithm': (0, 4),\n",
    "    'leaf_size': (2, 50),\n",
    "    'p': (0.001, 2)\n",
    "}\n",
    "\n",
    "\n",
    "# Set the optimizer #\n",
    "optimizer = BayesianOptimization(\n",
    "    f=obj_knn, pbounds=pbounds, random_state=seed)\n",
    "\n",
    "\n",
    "# Call maximizer #\n",
    "optimizer.maximize(init_points = 50, n_iter = 450)\n",
    "\n",
    "\n",
    "# Pull best info #\n",
    "best_hypers = optimizer.max['params']\n",
    "best_mse = optimizer.max['target']\n",
    "\n",
    "\n",
    "# Replace weights with string #\n",
    "if best_hypers['weights'] <= 0.5:\n",
    "    best_hypers['weights'] = 'uniform'\n",
    "else:\n",
    "    best_hypers['weights'] = 'distance'\n",
    "    \n",
    "    \n",
    "# Replace algorithm with string #\n",
    "if best_hypers['algorithm'] <= 1.0:\n",
    "    best_hypers['algorithm'] = 'auto'\n",
    "elif best_hypers['algorithm'] <= 2.0:\n",
    "    best_hypers['algorithm'] = 'ball_tree'\n",
    "elif best_hypers['algorithm'] <= 3.0:\n",
    "    best_hypers['algorithm'] = 'kd_tree'\n",
    "else:\n",
    "    best_hypers['algorithm'] = 'brute'\n",
    "    \n",
    "\n",
    "# Replace p #\n",
    "if best_hypers['p'] <= 1.0:\n",
    "    best_hypers['p'] = 1\n",
    "elif best_hypers['p'] <= 1.0 and best_hypers['algorithm'] != 'brute':\n",
    "    best_hypers['p'] = 1\n",
    "else:\n",
    "    best_hypers['p'] = 2\n",
    "    \n",
    "\n",
    "\n",
    "# Fill comparison matrix #\n",
    "train_compare = pd.concat([train_compare,\n",
    "                           pd.DataFrame({'Model' : 'KNN_Reg',\n",
    "                            'RMSE': np.sqrt(best_mse * -1),\n",
    "                            'hypers': [best_hypers]})], ignore_index = True)\n",
    "\n",
    "train_compare = train_compare.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af5b161",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be4c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function for network #\n",
    "def obj_net(batch_size, epochs, activation, num_nodes,\n",
    "            num_hidden_layers, learning_rate, rate, optimizer):\n",
    "    \"\"\"\n",
    "    The objective of this function is to minimize the error of the\n",
    "    neural network\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_size : Int\n",
    "        The number of cases to include in each batch.\n",
    "    epochs : Int\n",
    "        Number of runs through the data when updating weights.\n",
    "    activation : String\n",
    "        Type of activation function for the layer.\n",
    "    num_nodes : Int\n",
    "        Number of nodes to include in the hidden layer.\n",
    "    num_hidden_layers : Int\n",
    "        Number of hideen layers in the model.\n",
    "    learning_rate : Float\n",
    "        How much to change the model with each model update.\n",
    "    rate : Float\n",
    "        Dropout rate for each hidden layer to prevent overfitting.\n",
    "    optimizer : String\n",
    "        Optimizer to use for the model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error : Float\n",
    "        Cross validation returns root mean error that is later\n",
    "        convereted into RMSE in the comparison frame.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set Optimizer #\n",
    "    if optimizer <= 0.33:\n",
    "        optimizer = optimizers.Adam(learning_rate = learning_rate)\n",
    "    \n",
    "    elif optimizer <= 0.66:\n",
    "        optimizer = optimizers.Adagrad(learning_rate = learning_rate)\n",
    "    \n",
    "    else:\n",
    "        optimizer = optimizers.RMSprop(learning_rate = learning_rate)\n",
    "        \n",
    "    # Set activation function #\n",
    "    if activation <= 0.33:\n",
    "        activation = 'relu'\n",
    "        \n",
    "    elif activation <= 0.66:\n",
    "       activation = 'sigmoid'\n",
    "       \n",
    "    else:\n",
    "       activation = 'tanh'\n",
    "       \n",
    "    # Instantiate model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Set input layer #\n",
    "    model.add(Dense(int(num_nodes), activation = activation, \n",
    "                    input_shape = (X_train.shape[1],)))\n",
    "    \n",
    "    # Set hidden layer with batch normalizer #\n",
    "    for _ in range(int(num_hidden_layers)):\n",
    "        model.add(Dense(int(num_nodes), activation = activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(rate = rate, seed = seed))\n",
    "    \n",
    "    # Add output layer #\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Set compiler #\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = 'mean_squared_error')\n",
    "    \n",
    "    # Set early stopping #\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                                   patience=15, \n",
    "                                   restore_best_weights=True)\n",
    "    \n",
    "    # Create model #\n",
    "    reg = KerasRegressor(model = lambda : model,\n",
    "                         batch_size = int(batch_size),\n",
    "                         epochs = int(epochs),\n",
    "                         validation_split = 0.2,\n",
    "                         callbacks = [early_stopping],\n",
    "                         random_state = seed)\n",
    "\n",
    "    # Cross validation and mean MSE #\n",
    "    error = cross_val_score(reg, X_train, np.ravel(y_train), cv=cv,\n",
    "                        scoring='neg_mean_squared_error').mean()\n",
    "\n",
    "    # Return error #\n",
    "    return error\n",
    "\n",
    "# Define search space #\n",
    "pbounds = {\n",
    "    'batch_size': (50, 1460),\n",
    "    'epochs': (5, 500),\n",
    "    'learning_rate': (0.001, 0.15),\n",
    "    'num_nodes': (5, 80),\n",
    "    'num_hidden_layers': (2, 20),\n",
    "    'activation': (0, 1),\n",
    "    'rate': (0.0, 0.9),\n",
    "    'optimizer': (0, 1)\n",
    "}\n",
    "\n",
    "\n",
    "# Set the optimizer #\n",
    "optimizer = BayesianOptimization(f=obj_net, pbounds=pbounds,\n",
    "                                 random_state=seed)\n",
    "\n",
    "\n",
    "# Call the maximizer #\n",
    "optimizer.maximize(init_points=50, n_iter=450)\n",
    "\n",
    "\n",
    "# Pull best info #\n",
    "best_hypers = optimizer.max['params']\n",
    "best_mse = optimizer.max['target']\n",
    "\n",
    "\n",
    "# Replace optimizer and learning rate #\n",
    "if best_hypers['optimizer'] <= 0.33:\n",
    "    best_hypers['optimizer'] = optimizers.Adam(learning_rate = best_hypers['learning_rate'])\n",
    "    \n",
    "elif best_hypers['optimizer'] <= 0.66:\n",
    "    best_hypers['optimizer'] = optimizers.Adagrad(learning_rate = best_hypers['learning_rate'])\n",
    "    \n",
    "else:\n",
    "    best_hypers['optimizer'] = optimizers.RMSprop(learning_rate = best_hypers['learning_rate'])\n",
    "    \n",
    "    \n",
    "# Replace activation with string #\n",
    "if best_hypers['activation'] <= 0.33:\n",
    "    best_hypers['activation'] = 'relu'\n",
    "        \n",
    "elif best_hypers['activation'] <= 0.66:\n",
    "      best_hypers['activation'] = 'sigmoid'\n",
    "       \n",
    "else:\n",
    "     best_hypers['activation'] = 'tanh'\n",
    "\n",
    "\n",
    "# Fill comparison matrix #\n",
    "train_compare = pd.concat([train_compare,\n",
    "                           pd.DataFrame({'Model' : 'Neural_Net',\n",
    "                            'RMSE': np.sqrt(best_mse * -1),\n",
    "                            'hypers': [best_hypers]})], ignore_index = True)\n",
    "\n",
    "train_compare = train_compare.sort_values('RMSE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
